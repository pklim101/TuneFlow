services:
  myllamafactory:
    build:
      dockerfile: ./Dockerfile
      context: ../..
      args:
        INSTALL_BNB: false
        INSTALL_VLLM: false
        INSTALL_DEEPSPEED: false
        INSTALL_FLASHATTN: false
        PIP_INDEX: https://pypi.org/simple
    container_name: myllamafactory
    volumes:
      - ../../hf_cache:/root/.cache/huggingface
      - ../../ms_cache:/root/.cache/modelscope
      - ../../data:/app/data
      - ../../output:/app/output
    ports:
      - "7861:7861"
      - "8001:8001"
    ipc: host
    tty: true
    stdin_open: true
    command: bash
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: "all"
            capabilities: [gpu]
    restart: unless-stopped
    environment:  # set environment
      - GRADIO_SERVER_NAME=0.0.0.0
      - HF_ENDPOINT=https://hf-mirror.com
